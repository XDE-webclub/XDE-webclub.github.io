

## Introduction：人工智能概述

### 人工智能概念与分支

- 人工智能（Artificial Intelligence）是让各类机器载体上模拟并拥有类似生物的智能，让机器可以进行感知、学习、识别、推理等行为的计算机科学技术。

- 人工智能是计算机科学的分支，涉及领域包括计算机视觉（Computer Vision，CV）、自然语言处理（Natural Language Processing，NLP）、语音识别（Voice Recognition）、语音生成（Text to Speech，TTS）、知识图谱（Knowledge Graph）等。

- 机器学习是人工智能的核心，现在最前沿的AI技术的主流算法都是基于神经网络和强化学习。

- 从学术角度来看，人工智能有三大学派：符号主义（Symbolicism）、联结主义（Connectionism）、行为主义（Actionism）。

| 学派分类 | 符号主义                                        | 连结主义                                         | 行为主义                                              |
|------|---------------------------------------------|----------------------------------------------|---------------------------------------------------|
| 思想起源 | 数理逻辑：基于统计方法，通过建模预测让机器通过计算来模拟人的智能，实现识别、预测等任务 | 仿生学：生物智能是由神经网络产生的，可以通过人工方式构造神经网络，训练神经网络产生智能。 | 生物的智能来自对外界的复杂环境进行感知和适应，通过与环境和其他生物之间的相互作用，产生更强的智能。 |
| 代表算法 | 朴素贝叶斯，逻辑回归，决策树，支持向量机                        | 神经网络 Neural Network                          | 强化学习 Reinforcement Learning                       |

### 机器学习

- 机器学习（Machine Learning,ML）是实现人工智能的核心方法，是从有限的观测数据中“学习”（or“猜测”）出一个具有一般性的规律，并利用这些规律对未知数据进行预测的方法。

- 传统的机器学习主要关注如何学习一个预测模型，一般需要首先将数据表示为一组特征（Feature），特征的表示形式可以是连续的数值/离散的符号等形式。而后将这些特征输入到预测模型，并输出预测结果。这类机器学习可以看作是浅层学习（Shallow Learning），其重要特点是不涉及特征学习，其特征主要靠人工经验或者特征转换方法来提取。

### 机器学习的分类：根据学习范式分类

根据学习范式的不同，机器学习可分为有监督学习、无监督学习、自监督学习和强化学习

#### 有监督学习

- 有监督学习（Supervised Learning）：是机器学习中一种常见的学习范式，其基本思想是利用带有标签的训练数据来训练模型，从而使其能够从输入数据中学习到输入与输出之间的映射关系，然后可以利用这个映射关系对新的未标签数据进行预测。

- 有监督学习的训练集要包括输入（特征）和输出（目标），其中，输出是人工标注的。

有监督学习的典型应用

1. 分类（Classification）：预测输入样本属于哪个类别或者类别的概率分布。典型的例子包括垃圾邮件分类、图像分类等。
2. 回归（Regression）：预测输入样本的数值输出，通常是连续的实数值。典型的例子包括房价预测、股票价格预测等。
3. 目标检测（Object Detection）：在图像或者视频中检测出目标物体的位置和类别。例如自动驾驶中识别出道路上的车辆、行人、交通标志等；或者人脸识别中判断出哪一部分是人脸。
4. 序列生成（Sequence Generation）：根据输入的序列生成输出的序列，如机器翻译、音乐生成等。
5. 序列标注（Sequence Labeling）：序列标注是一种常见的机器学习任务，其中输入数据通常是序列数据，例如文本、语音、生物信息学等。有监督学习可以对输入的序列中的每个元素进行标签预测，如命名实体识别（Named Entity Recognition，NER，指自然语言处理中，能从文本中提取如人名、地名、组织名、日期、时间、金额等具有特定意义的实体或实体类别）、语音识别（Speech Recognition）等。

常见的有监督学习的算法包括K近邻（KNeighborsClassifier）、线性回归（Linear Regression）、逻辑回归（Logistic Regression）、朴素贝叶斯（GaussianNB）、决策树（Decision Trees）、支持向量机（Support Vector Machines）、随机森林（Random Forests）等。

#### 无监督学习

- 无监督学习（Unsupervised Learning）是机器学习中一种常见的学习范式，其目标是从未标记的数据中自动地发现数据中的结构、模式、关联或者表示，而无需使用人工标签或者先验知识的指导。

无监督学习的应用非常广泛，包括但不限于以下几个方面：

1. 聚类（Clustering）：将数据集中的样本根据相似性进行自动分类，形成不同的簇。典型的例子包括顾客分群、社交网络用户聚类等。
2. 异常检测（Anomaly Detection）：识别数据中的异常样本，这些样本与正常样本不同，可能是潜在的异常事件或异常行为。典型的例子包括反洗钱、信用卡欺诈检测等。
3. 降维（Dimensionality Reduction）：将高维数据映射到低维空间，保留数据的主要信息，去除冗余和噪音。典型的例子包括图像压缩等。
4. 关联规则挖掘（Association Rule Mining）：从大规模数据集中发现频繁出现的关联规则，用于发现数据中的潜在关联关系。典型的例子包括购物篮分析、推荐系统等。

常见的无监督学习算法包括聚类算法如K均值聚类（K-means clustering），降维算法如主成分分析（PCA）等。

#### 强化学习

- 强化学习（Reinforcement Learning）是一种机器学习方法，用于通过玩家（Agent）与环境（Environment）的交互来学习如何做出合适的决策，以最大化预期的累积奖励。

在强化学习中，Agent通过与环境的相互作用，观察环境的状态（State），执行不同的动作（Action），接收环境的反馈（奖励信号，奖励Reward），并根据反馈来调整其行为策略（Policy），从而逐渐学习如何在不同的环境中做出最优的决策。

强化学习的关键特点包括以下几点：

1. Environment和State：强化学习中的Agent与Environment进行交互，Agent通过观察Environment的State来感知环境的变化并进行决策。（eg. 我们开车的时候与我们所看到的路况进行交互，根据路上的行人、其他汽车、指示牌等的状态，选择怎么去打方向盘。那么整个汽车所在的公路就是Environment，公路上具体的路况就是State）
2. Action和Policy：Agent可以采取不同的Action来影响Environment的State。那么在什么样的State下，Agent要采取什么样的Action？Agent是基于一定的策略Policy来选择要执行的Action的，而这个Policy往往是一个以当前State为自变量，要执行的Action为输出的一个函数。（eg. 我们在路上怎么打方向盘，就是Action。在什么样的路况下我们会怎么去打方向盘，就是Policy。我们打方向盘这件事情会影响环境的状态；而环境的状态改变又会返回来决定我们该怎么打方向盘。）
3. Reward和Goal：环境向Agent提供奖励信号，用于反馈Agent的行为质量。Agent的目标是通过最大化预期的累积奖励，以此来学习如何做出最佳决策。（eg. 路边的其他车会向你打鸣告诉你你开的不好，违规了的话交警会对你处罚，这就是一个负的Reward。你的Goal可能是以最快的速度最安全、不违规的到达目的地，你通过不断的与环境交互，学习出一个最佳的开车Policy，从而实现这个目标。）
4. 试错学习和优化：强化学习中的Agent通过与环境的交互来不断学习和优化其策略，这是一个不断试错的过程，State和Action之间的往复交互是强化学习的主体部分，所以是Trial and Error Learning。强化学习的最终目标是一个好的策略。
5. 价值决定策略：价值，就是预期将来会得到的所有奖励之和。（下围棋的时候，如果一步棋决定了胜局，那么这步棋就特别有价值！）

强化学习不要求预先给定任何数据，而是通过接收环境对动作的奖励（反馈）获得学习信息并更新模型参数。

强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。

强化学习的典型应用

1. 自动驾驶车辆：强化学习在自动驾驶领域中也得到了广泛应用，例如通过训练智能车辆在不同道路条件下学习驾驶策略，包括避免碰撞、减少能耗等。（自动驾驶中既要用有监督学习的图像识别技术去理解当前的State，又要用RL的技术去不断优化驾驶策略）
2. 游戏与游戏玩家：强化学习被广泛用于电子游戏中，例如通过训练智能代理在复杂的游戏环境中进行游戏策略决策，如围棋、国际象棋等。同时，强化学习还可以用于训练游戏中的虚拟角色，使其能够自主学习和优化其行为策略。（eg. AlphaGo）
3. 机器人控制：强化学习在机器人领域中有广泛的应用，包括自主导航、机器人手臂控制、无人机控制等。通过强化学习，机器人可以从与环境的交互中学习控制策略，以完成复杂的任务。

常见的强化学习的算法：价值学习、策略学习、Actor-Critic Method。各种神经网络是实现强化学习的主要工具。

#### 组合与变种

##### 自监督学习

自监督学习本身是无监督学习的一种范式，因为它也不需要人工去打标签，它利用辅助任务（Pretext）从大规模的无监督数据中挖掘自身的监督信息，通过这种构造的监督信息对网络进行训练，从而可以学习到对下游任务有价值的表征。

例如我输入了:台湾大学

机器随机的遮住了一个词，这里遮住了“湾”。而后机器要去做“预测这个被遮住的词应该是什么”的任务，而且任务的标准答案机器当然知道，就是“湾”字。因此，机器就可以自动比较自己输出的答案和标准答案差在哪儿，从而去更正自己了。

##### 有监督学习与无监督学习并用

无监督学习和有监督学习都是机器学习的范式，两者经常在同一个算法中被一同使用。

在推荐系统中，无监督学习方法可以用于从大量的未标记数据中学习用户行为模式、内容特征等信息，从而为用户提供个性化的推荐。例如，TikTok的推荐算法可能通过无监督学习方法，如聚类（Clustering）、降维（Dimensionality Reduction）等，对用户上传的大量视频数据进行分析和处理，从中提取出视频的特征，如视频的内容、情感、时长等，并根据用户的观看历史、行为偏好等信息，将相似的视频聚类在一起，从而实现相似内容的推荐。

监督学习方法也常常用于推荐算法中，通过使用标记的样本数据，如用户的历史行为数据（如点击、点赞、评论等）和用户的反馈（如用户的喜好、兴趣等），来训练模型进行推荐预测。

### 机器学习的分类：根据网络的深度和复杂性分类

#### 浅层学习（Shallow Learning）

浅层学习通常指的是使用较少层次、较简单结构的机器学习模型，例如传统的线性回归、逻辑回归、决策树、支持向量机等。这些模型通常只有一层或者很少的层，且每一层的特征表示较为简单和浅显，不具备较强的抽象能力。

##### 特征（Feature）

特征（Feature），是指从原始数据中提取出的、用于表示样本的属性或信息。

在机器学习模型中，特征被用作模型的输入，用于表示样本的不同属性，从而帮助模型进行学习和预测。因此，首先要将数据表现为一组特征，而后才能将其输入，进行机器学习。

##### 特征工程（Feature Engineering）

特征工程（Feature Engineering）是指在机器学习和数据挖掘中，通过对原始数据进行处理、转换和提取，生成新的特征或选择合适的特征，从而改进模型性能和提高预测准确性的过程。

如果想要建立起一个识别财务报表是否舞弊的模型：f（财报的特征）=是否舞弊，那么输入给模型的参数的选择有很多：资产负债率、盈利质量、流动比率、速动比率等等。那么选择哪些参数、输入多少参数输入给模型，其实都会对模型最后的识别性能有很高的影响。这个挖掘和选择特征的过程就是特征工程

#### 深度学习（Deep Learning）

- 深度学习是一种使用深层次、复杂结构的神经网络模型进行学习的方法。深度学习模型通常有多个层次（通常超过3层）的神经元组成，每一层的输出作为下一层的输入，从而形成层层叠加的结构。深度学习模型可以通过在多个层次上学习到更加抽象和高级的特征表示，从而能够更好地捕捉数据中的内在结构和特性。

- 为了学习一种好的表示，需要构建具有一定“深度”的模型，并通过学习算法来让模型自动学习出好的特征表示（从底层特征，到中层特征，再到高层特征），从而最终提升预测模型的准确率。所谓“深度”是指原始数据进行非线性特征转换的次数．如果把一个表示学习系统看作一个有向图结构，深度也可以看作从输入节点到输出节点所经过的最长路径的长度．

深度学习可以通过底层特征、中间特征、高层特征的表示学习，去避免浅层学习中在做特征处理（特征提取、特征选择）时的特征工程的。

在一些复杂任务中，传统机器学习方法需要将一个任务的输入和输出之间人为地切割成很多子模块（或多个阶段），每个子模块分开学习。比如一个自然语言理解任务，一般需要分词、词性标注、句法分析、语义分析、语义推理等步骤。

这种学习方式有两个问题：

- 一是每一个模块都需要单独优化，并且其优化目标和任务总体目标并不能保证一致；
- 二是错误传播，即前一步的错误会对后续的模型造成很大的影响．这样就增加了机器学习方法在实际应用中的难度．

端到端学习是指在学习过程中不进行分模块或分阶段训练，直接优化任务的总体目标．在端到端学习中，一般不需要明确地给出不同模块或阶段的功能，中间过程不需要人为干预．端到端学习的训练数据为“输入-输出”对的形式，无须提供其他额外信息．深度学习模型通常可以被看作一种端到端学习的工具，因为它们能够从原始输入到最终输出进行端到端的映射。

##### 表示/表征（Representation）

表示（Representation）则通常指的是将数据以某种形式进行编码或者表示的方式，可以是在特征空间中的表示，也可以是在其他空间中的表示。在深度学习中，表征通常是由模型自动学习得到的，例如通过神经网络的隐藏层进行特征提取和表示学习（后面讲MLP的时候就会提到）。这种自动学习的表现通常比手工设计的特征更能够捕捉数据中的复杂模式和关系，从而提升模型的性能。

##### 局部表示 Local Representation

局部表示，也称为离散表示或符号表示。 以颜色表示为例，我们可以用很多词来形容不同的颜色1，除了基本的“红” “蓝”“绿”“白”“黑”等之外，还有很多以地区或物品命名的，比如“中国红”“天蓝色”“咖啡色”“琥珀色”等．如果以不同名字来命名不同的颜色，这种表示方式叫作局部表示。

局部表示通常可以表示为One-hot向量的形式，假设假设所有颜色的名字构成一个词表 𝒱，词表大小为 |𝒱|．我们可以用一个|𝒱|维的one-hot向量来表示每一种颜色．在第𝑖种颜色对应的one-hot向量中，第𝑖 维的值为1，其他都为0．

即：[1,0,0,0,0,0],[0,1,0,0,0,0]....

优点：

1. 这种离散的表示方式具有很好的解释性，有利于人工归纳和总结特征，并通过特征组合进行高效的特征工程；
2. 通过多种特征组合得到的表示向量通常是稀疏的二值向量，当用于线性模型时计算效率非常高．

不足:
1.one-hot向量的维数很高（维度爆炸），且不能扩展．如果有一种新的颜色，我们就需要增加一维来表示；
2.不同颜色之间的相似度都为0，因为这些向量全部正交。即我们无法知道“红色”和“中国红”的相似度要高于“红色”和“黑色”的相似度。

##### 分布式表示（Distributed Representation）

分布式表示是一种将数据表示为多维向量的方法，其中每个维度都包含有关数据的一部分信息。

例如，我们用RGB值来表示颜色，不同的颜色对应到R、G、B三维空间中一个点，这种表示方法即为分布式表示。

分布式表示在深度学习中得到广泛应用，例如在神经网络中使用嵌入层（Embedding Layer）对输入数据进行分布式表示

相比于让所有颜色的名字构成一个词表 𝒱，我们现在用一个三维的向量就可以表示出所有的颜色了。

此外，不同的颜色之间的相似度也变得很容易计算，只需要去算他们的余弦相似度/欧式距离等就可以了。

分布式表示具有许多优势，例如能够更好地捕捉数据的多样性、泛化性能较好、能够处理未知数据等。例如，在自然语言处理中，分布式词向量（如Word2Vec、GloVe等）将单词表示为多维向量，每个维度都包含了单词在不同语义和语法属性上的信息，从而在词汇表很大的情况下，能够更好地表示单词之间的语义和语法关系。

##### 表征学习（Representation Learning）

- 表征学习（Representation Learning）是一种自动化地从原始数据中学习有效的特征表示的方法。它通过深度神经网络等模型，从原始数据中自动学习层次化、抽象化的特征表示，而无需手工设计特征。表征学习能够从数据中提取出更丰富、更高级的特征，从而更好的描述数据，有助于提高模型的性能和泛化能力。

- 要学到一种好的高层语义表示（一般是分布式表示），通常需要从底层特征开始，经过多步骤的非线性转换才能得到（#之所以要是非线性，是因为连续多次的线性转换归根到底还是等价于一次线性转换）。表征学习与深度学习天然相关，因为深度神经网络所具有的深层结构的优点是可以增加特征的重用性，从而指数级的增加表示能力。因此，表征学习的关键是构建具有一定深度的多层次特征表示。


