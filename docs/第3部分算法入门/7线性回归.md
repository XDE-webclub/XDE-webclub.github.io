
## 线性回归

线性回归是利用连续性变量来估计实际数值（例如房价，呼叫次数和总销售额等）。

我们通过线性回归算法找出自变量和因变量间的最佳线性关系，图形上可以确定一条最佳直线。

这条最佳直线就是回归线。这个回归关系可以用Y=aX+b 表示。


```python 
import numpy as np
from sklearn.linear_model import LinearRegression

# 创建一些示例数据
X = np.array([[1], [2], [3], [4], [5]])  # 自变量
y = np.array([2, 4, 5, 4, 5])  # 因变量
# 创建线性回归模型
model = LinearRegression()

# 拟合模型
model.fit(X, y)

# 打印回归系数和截距
print("回归系数 (斜率):", model.coef_)
print("截距:", model.intercept_)


# 预测新数据点
new_data_point = np.array([[6]])  # 要预测的新数据点
predicted_value = model.predict(new_data_point)
print("预测值:", predicted_value)

```


### 简单示例


```python 
from sklearn import datasets
from sklearn.linear_model import LinearRegression
# 加载数据

loaded_data = datasets.fetch_california_housing()
data_X = loaded_data.data
data_y = loaded_data.target

model = LinearRegression()
model.fit(data_X, data_y)

# 预测前四所房屋价格
print(model.predict(data_X[:4, :]))
# 真实价格
print(data_y[:4])
```


### 效果评估


```python 
print(model.get_params())# 获取模型参数
print(model.score(data_X, data_y)) # R^2 coefficient of determination
# 这意味着数据集中因变量的 60% 的变异性已得到考虑，而其余 40% 的变异性仍未得到解释。
```


### 查看模型属性


```python 
# 打印回归系数和截距
print("回归系数 (斜率):", model.coef_)
print("截距:", model.intercept_)
```

