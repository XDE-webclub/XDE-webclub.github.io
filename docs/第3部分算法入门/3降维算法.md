
## 降维算法

作为一名数据科学家，我们手上的数据有非常多的特征。

虽然这听起来有利于建立更强大精准的模型，但它们有时候反倒也是建模中的一大难题。

怎样才能从1000或2000个变量里找到最重要的变量呢？

这种情况下降维算法及其他算法，如决策树，随机森林，PCA，因子分析，相关矩阵，和缺省值比例等，就能帮我们解决难题。


```python 
from sklearn.decomposition import PCA
import numpy as np

# 创建一些示例数据
X = np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6]])  # 特征矩阵

# 创建PCA降维模型
n_components = 2  # 指定要降维到的维度
model = PCA(n_components=n_components)

# 拟合模型并进行降维
X_reduced = model.fit_transform(X)

print("原始数据形状:", X.shape)
print("降维后数据形状:", X_reduced.shape)
print("降维后数据:")
print(X_reduced)
```


### 简单示例


```python 
from sklearn.decomposition import PCA
import numpy as np

from sklearn.datasets import load_iris
# 加载数据
iris = load_iris()
iris_X = iris.data
iris_y = iris.target

# 创建PCA降维模型
n_components = 3  # 指定要降维到的维度
model = PCA(n_components=n_components)

# 拟合模型并进行降维
X_reduced = model.fit_transform(iris_X)
```


### 效果评估


```python 
print("原始数据形状:", iris_X.shape)
print("降维后数据形状:", X_reduced.shape)
print("降维后数据:")
print(X_reduced)
```


### 三维可视化结果


```python 
import matplotlib.pyplot as plt

fig = plt.figure()
# 创建一个3d的画布
ax = fig.add_subplot(projection='3d')
 
xs = list(X_reduced[:, 0])
ys = list(X_reduced[:, 1])
zs = list(X_reduced[:, 2])
data_points = [(x, y, z) for x, y, z in zip(xs, ys, zs)]

# 把分类的0、1、2替换为绿色、红色、蓝色
color={0:'green',1:'red',2:'blue'}
colors = [color[i] if i in color else i for i in iris_y]

for data, color in zip(data_points, colors):
    x, y, z = data
    ax.scatter(x, y, z, c=color)
```

