
### 效果评估


```python 
# .score()返回的是准确度
# 和之前学习的accuracy_score、cross_val_score一样都是检测准确度的方法
print('预测是准确度为{}%'.format(clf.score(X_test, y_test)*100))
```


### 数据normalization


```python 
from sklearn import preprocessing
# normalization是指将数据按比例缩放，使之落入一个小的特定区间
# 先标准化数据再使用数据
X2 = preprocessing.scale(X)    # normalization step
# print(X2)
X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y, test_size=0.3)

clf2 = svm.SVC()
clf2.fit(X2_train, y2_train)
print('预测是准确度为{}%'.format(clf2.score(X2_test, y2_test)*100))
# 简单验证后发现处理后的数据显然表现更好，预测是准确度为98.83040935672514%

from sklearn import model_selection

# 但是并不是每次验证得到的结果都是一致的，验证具有随机性，因此需要交叉验证
# 把数据分成5份，分别做测试集，提取分数并求平均值，显然处理后的数据表现更好
print(model_selection.cross_validate(clf,X_test, y_test,cv=5)['test_score'].mean())
print(model_selection.cross_validate(clf2,X2_test, y2_test,cv=5)['test_score'].mean())
'''
0.8947899159663866 # 未处理的数据
0.9825210084033614 # 处理后的数据
'''
```


### 防止过拟合


```python 
from __future__ import print_function
from sklearn.model_selection import  learning_curve
from sklearn.datasets import load_digits
from sklearn.svm import SVC
import matplotlib.pyplot as plt
import numpy as np
# 载入数据
digits = load_digits()
X = digits.data
y = digits.target

# learning_curve()函数用于计算在不同大小的训练集上训练得到的模型在验证集上的得分情况
# 进而分析模型是否过拟合或者欠拟合
# 这里我们使用SVC模型，gamma=0.01
# gamma参数用于控制模型的复杂度，gamma越大，模型越复杂，越容易过拟合
# 通过train_sizes参数来指定训练集的大小
# 通过cv参数来指定交叉验证的次数
# 通过scoring参数来指定评价指标，这里使用的是负均方误差
train_sizes, train_loss, test_loss= learning_curve(
        SVC(gamma=0.01), X, y, cv=10, scoring="neg_mean_squared_error",
        train_sizes=[0.1, 0.25, 0.5, 0.75, 1])

# 计算平均值和标准差
train_loss_mean = -np.mean(train_loss, axis=1)
test_loss_mean = -np.mean(test_loss, axis=1)

# 绘制曲线
# 这里我们使用的是负均方误差，因此数值越小，模型越好
# ro-表示红色圆形实线，go-表示绿色圆形实线
plt.plot(train_sizes, train_loss_mean, 'ro-', 
             label="Training")
plt.plot(train_sizes, test_loss_mean, 'go-', 
             label="test-Cross-validation")
plt.xlabel("Training examples")
plt.ylabel("Loss")
# 显示图例,loc="best"表示自动选择最佳位置
plt.legend(loc="best")
plt.show()
# 这个图表示：
# 刚开始只有200个数据的时候，误差很大，这是因为数据量太少，模型无法很好地拟合数据
# 随着数据量的增加，误差逐渐减小，这是因为模型可以更好地拟合数据
# 但是随着数据集进一步增加，误差反而增大了，这说明模型出现了过拟合
```

