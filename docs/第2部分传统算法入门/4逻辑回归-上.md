
## 逻辑回归

假设你的一个朋友让你回答一道题。

可能的结果只有两种：你答对了或没有答对。

为了研究你最擅长的题目领域，你做了各种领域的题目。

那么这个研究的结果可能是这样的：

如果是一道十年级的三角函数题，你有70%的可能性能解出它。

但如果是一道五年级的历史题，你会的概率可能只有30%。

逻辑回归就是给你这样的概率结果。


```python 
import numpy as np
from sklearn.linear_model import LogisticRegression

# 创建一些示例数据
X = np.array([[1], [2], [3], [4], [5]])  # 自变量
y = np.array([0, 0, 1, 1, 1])  # 因变量，0表示负类，1表示正类

# 创建逻辑回归模型
model = LogisticRegression()

# .fit()方法用于拟合模型，即训练模型x
model.fit(X, y)

# 预测新数据点
new_data_point = np.array([[6]])  # 要预测的新数据点
# .predict()方法预测新数据点的类别
predicted_class = model.predict(new_data_point)
# .predict_proba()方法预测新数据点的概率
predicted_probability = model.predict_proba(new_data_point)

print("预测类别:", predicted_class)
print("预测概率 (负类, 正类):", predicted_probability)
print(type(predicted_probability))
predicted_probability
```


### 简单示例


```python 
from sklearn import datasets
from sklearn.model_selection import train_test_split  
from sklearn.preprocessing import StandardScaler  
from sklearn.linear_model import LogisticRegression


datasets

# 加载数据集
digits = datasets.load_digits()  
  
# 获取特征和目标变量  
X = digits.data  
y = digits.target  
  
# 数据预处理：随机分割训练集和测试集 , 如果不指定 random_state，每次运行结果都不一样。42为约定俗成的随机数种子
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 数据标准化  
scaler = StandardScaler()  
# .fit_transform()方法先拟合数据，再标准化。和降维算法的语法一致
X_train = scaler.fit_transform(X_train)  
# .transform()方法直接使用在测试集上进行标准化操作
X_test = scaler.transform(X_test)  
  
# 创建Logistic Regression模型  , 如果不指定 random_state，每次运行结果都不一样。42为约定俗成的随机数种子
model = LogisticRegression(random_state=42)  
  
# .fit()方法用于拟合模型，即训练模型
model.fit(X_train, y_train)  
  
# .predict()方法预测新数据点的类别
y_pred = model.predict(X_test)  

```

